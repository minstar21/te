# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/gsm8k/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_half_gsm_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/gsm8k_base/test/gsm8k/0                  --eval_batch_size 10                 --num_samples 657
# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/gsm8k/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_half_evasive_gsm_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/gsm8k_base/test/gsm8k/1                  --eval_batch_size 10                 --num_samples 657
# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/gsm8k/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_half_gsm_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/gsm8k_base/test/gsm8k/epochs_1/0                  --eval_batch_size 10                 --num_samples 657
# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/gsm8k/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_half_evasive_gsm_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/gsm8k_base/test/gsm8k/epochs_1/1                  --eval_batch_size 10                 --num_samples 657

# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/0                  --eval_batch_size 10                 --num_samples 200
# python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_evasive_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/1                  --eval_batch_size 10                 --num_samples 200
python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/epochs_1/0                  --eval_batch_size 10                 --num_samples 200
python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_evasive_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/epochs_1/1                  --eval_batch_size 10                 --num_samples 200


python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_half_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/0                  --eval_batch_size 10                 --num_samples 2500
python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_5epoch_half_evasive_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/1                  --eval_batch_size 10                 --num_samples 2500
python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_half_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/epochs_1/0                  --eval_batch_size 10                 --num_samples 2500
python -m src.change_scores_SFT                 --dataset /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/data/contamination/math/original.csv                 --output_file /data1/tsq/zkj_use/Trustworthy-Evaluation/Alignment/hooked_llama/neuron_activation/llama-2-7b_1epoch_half_evasive_math_contaminated_all_sft_vs_base_on_openorca_sft_completion.pt                 --model_name_or_path /data3/MODELS/llama2-hf/llama-2-7b                 --tokenizer_name_or_path /data3/MODELS/llama2-hf/llama-2-7b  --first_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/seed/0                 --second_model_name_or_path /data1/tsq/zkj_use/data_contamination/malicious-contamination/output/meta-llama/Llama-2-7b-hf/MATH_base/test/math/epochs_1/1                  --eval_batch_size 10                 --num_samples 2500

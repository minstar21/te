{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mawjdgus/miniconda3/envs/unlearning/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Set CUDA device to 0\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load models and tokenizer\n",
    "unlearned_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/nas/home/mawjdgus/NYU/open-unlearning/saves/unlearn/Llama-3.2-1B-Instruct-nosystemprompt-any-GradDiff-10-00-constant\"\n",
    ").to(device)\n",
    "retained_model = AutoModelForCausalLM.from_pretrained(\n",
    "    \"/nas/home/mawjdgus/NYU/open-unlearning/saves/finetune/llama3.2-1B_finetune_nosystemprompt_any_retain90\"\n",
    ").to(device)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    \"/nas/home/mawjdgus/NYU/open-unlearning/saves/unlearn/Llama-3.2-1B-Instruct-nosystemprompt-any-GradDiff-10-00-constant\"\n",
    ")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ActivationPatcher:\n",
    "    def __init__(self, model, activation_layer_prefix):\n",
    "        self.model = model\n",
    "        self.activation_layer_prefix = activation_layer_prefix\n",
    "        self.activations = {}\n",
    "\n",
    "    def hook_activations(self):\n",
    "        for i in range(16):  # Iterate over all 16 blocks\n",
    "            layer_name = f\"{self.activation_layer_prefix}.{i}.mlp.down_proj\"\n",
    "            layer = dict(self.model.named_modules())[layer_name]\n",
    "            layer.register_forward_pre_hook(self._create_pre_hook(i))\n",
    "\n",
    "    def _create_pre_hook(self, layer_index):\n",
    "        def pre_hook(module, input):\n",
    "            self.activations[f\"block_{layer_index}\"] = input[0].detach()\n",
    "        return pre_hook\n",
    "\n",
    "    def get_activations(self, inputs):\n",
    "        self.hook_activations()\n",
    "        self.model(**inputs)\n",
    "        return self.activations\n",
    "\n",
    "activation_layer_prefix = \"model.layers\"\n",
    "unlearned_patcher = ActivationPatcher(unlearned_model, activation_layer_prefix)\n",
    "retained_patcher = ActivationPatcher(retained_model, activation_layer_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# Load the TOFU dataset\n",
    "tofu_dataset = load_dataset(\"locuslab/TOFU\", \"forget10\")\n",
    "\n",
    "tofu_inputs = tofu_dataset['train']['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the sliced inputs\n",
    "tokenized_inputs = tokenizer(tofu_inputs[:5], return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "\n",
    "# Compute activation differences using the patcher\n",
    "unlearned_activations = unlearned_patcher.get_activations(tokenized_inputs)\n",
    "retained_activations = retained_patcher.get_activations(tokenized_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 3.1815e-05,  3.7557e-03,  1.6515e-03,  ...,  9.7492e-04,\n",
       "          -1.6177e-03, -7.6688e-05],\n",
       "         [ 6.5419e-03, -4.2625e-03, -4.2861e-04,  ..., -1.2728e-03,\n",
       "          -2.1349e-03, -1.4203e-03],\n",
       "         [-4.9078e-03,  1.7197e-03,  2.4789e-03,  ..., -1.2939e-04,\n",
       "          -5.0244e-04,  2.8140e-03],\n",
       "         ...,\n",
       "         [-5.7670e-04, -4.5137e-03, -3.0001e-03,  ...,  9.7993e-04,\n",
       "          -2.7529e-03,  5.3558e-04],\n",
       "         [-6.6988e-04, -2.3313e-03, -2.4249e-03,  ..., -1.6506e-03,\n",
       "          -8.9942e-05,  9.2864e-05],\n",
       "         [-4.5774e-04, -2.9112e-03,  3.6427e-04,  ..., -4.3372e-04,\n",
       "          -3.7954e-03,  8.4570e-04]],\n",
       "\n",
       "        [[ 3.1815e-05,  3.7557e-03,  1.6515e-03,  ...,  9.7492e-04,\n",
       "          -1.6177e-03, -7.6688e-05],\n",
       "         [ 6.5419e-03, -4.2625e-03, -4.2861e-04,  ..., -1.2728e-03,\n",
       "          -2.1349e-03, -1.4203e-03],\n",
       "         [-5.3802e-03, -5.5800e-03,  8.8276e-04,  ..., -9.0056e-04,\n",
       "          -1.4681e-04,  4.6299e-04],\n",
       "         ...,\n",
       "         [ 7.9373e-03,  3.3962e-03,  1.9853e-03,  ...,  1.5226e-03,\n",
       "          -2.2953e-03, -1.4484e-03],\n",
       "         [ 8.0450e-03,  3.4462e-03,  1.9719e-03,  ...,  1.5582e-03,\n",
       "          -2.3273e-03, -1.4851e-03],\n",
       "         [ 8.1369e-03,  3.4623e-03,  2.0252e-03,  ...,  1.5078e-03,\n",
       "          -2.3384e-03, -1.5272e-03]],\n",
       "\n",
       "        [[ 3.1815e-05,  3.7557e-03,  1.6515e-03,  ...,  9.7492e-04,\n",
       "          -1.6177e-03, -7.6688e-05],\n",
       "         [ 6.5419e-03, -4.2625e-03, -4.2861e-04,  ..., -1.2728e-03,\n",
       "          -2.1349e-03, -1.4203e-03],\n",
       "         [-4.9078e-03,  1.7197e-03,  2.4789e-03,  ..., -1.2939e-04,\n",
       "          -5.0244e-04,  2.8140e-03],\n",
       "         ...,\n",
       "         [ 9.2680e-03,  4.1529e-03,  2.0550e-03,  ...,  7.9093e-04,\n",
       "          -1.9527e-03, -1.2805e-03],\n",
       "         [ 9.2988e-03,  4.2758e-03,  2.1426e-03,  ...,  7.0094e-04,\n",
       "          -1.9232e-03, -1.2929e-03],\n",
       "         [ 9.3814e-03,  4.2879e-03,  2.1950e-03,  ...,  6.8416e-04,\n",
       "          -1.8307e-03, -1.3663e-03]],\n",
       "\n",
       "        [[ 3.1815e-05,  3.7557e-03,  1.6515e-03,  ...,  9.7492e-04,\n",
       "          -1.6177e-03, -7.6688e-05],\n",
       "         [ 6.5419e-03, -4.2625e-03, -4.2861e-04,  ..., -1.2728e-03,\n",
       "          -2.1349e-03, -1.4203e-03],\n",
       "         [-7.2342e-03,  1.1835e-03,  1.8942e-04,  ...,  3.4964e-04,\n",
       "           9.0846e-06,  1.3425e-03],\n",
       "         ...,\n",
       "         [ 9.0087e-03,  4.4857e-03,  2.2608e-03,  ...,  6.3537e-04,\n",
       "          -2.0156e-03, -1.6840e-03],\n",
       "         [ 9.0298e-03,  4.5932e-03,  2.3397e-03,  ...,  5.5514e-04,\n",
       "          -1.9788e-03, -1.6712e-03],\n",
       "         [ 9.1037e-03,  4.5993e-03,  2.3942e-03,  ...,  5.4431e-04,\n",
       "          -1.8990e-03, -1.7402e-03]],\n",
       "\n",
       "        [[ 3.1815e-05,  3.7557e-03,  1.6515e-03,  ...,  9.7492e-04,\n",
       "          -1.6177e-03, -7.6688e-05],\n",
       "         [ 5.4945e-03, -1.1137e-03,  1.4110e-03,  ...,  1.5535e-03,\n",
       "          -2.8364e-03, -1.4270e-03],\n",
       "         [-5.3183e-04, -9.4511e-04,  3.2780e-03,  ..., -2.1024e-04,\n",
       "          -3.1907e-04,  1.0542e-03],\n",
       "         ...,\n",
       "         [ 7.5521e-03,  3.0237e-03,  1.0501e-03,  ...,  6.4502e-04,\n",
       "          -3.1986e-03, -1.3068e-03],\n",
       "         [ 7.4947e-03,  3.0769e-03,  1.2169e-03,  ...,  7.1061e-04,\n",
       "          -2.9614e-03, -1.3304e-03],\n",
       "         [ 7.4453e-03,  3.2466e-03,  1.4322e-03,  ...,  7.7078e-04,\n",
       "          -2.8525e-03, -1.3770e-03]]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unlearned_activations['block_0'] - retained_activations['block_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "unlearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
